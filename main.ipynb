{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "In this section we will load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.631879900Z",
     "start_time": "2024-01-15T16:09:13.781274400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from utils import train_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.648858700Z",
     "start_time": "2024-01-15T16:09:16.633322600Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.674840500Z",
     "start_time": "2024-01-15T16:09:16.649860500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path definitions\n",
    "colab_path = '/content/drive/MyDrive/NLP/project/'\n",
    "local_path = './data/'\n",
    "data_path = Path(local_path)\n",
    "\n",
    "train_data_path = data_path / 'MELD_train_efr.json'\n",
    "val_data_path = data_path / 'MELD_val_efr.json'\n",
    "test_data_path = data_path / 'MELD_test_efr.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.740755600Z",
     "start_time": "2024-01-15T16:09:16.664719500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       episode                                           speakers  \\\n0  utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n1  utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n2  utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n3  utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n4  utterance_4                       [Joey, Rachel, Joey, Rachel]   \n\n                                            emotions  \\\n0     [neutral, neutral, neutral, neutral, surprise]   \n1  [neutral, neutral, neutral, neutral, surprise,...   \n2  [neutral, neutral, neutral, neutral, surprise,...   \n3  [neutral, neutral, neutral, neutral, surprise,...   \n4                [surprise, sadness, surprise, fear]   \n\n                                          utterances  \\\n0  [also I was the point person on my company's t...   \n1  [also I was the point person on my company's t...   \n2  [also I was the point person on my company's t...   \n3  [also I was the point person on my company's t...   \n4  [But then who? The waitress I went out with la...   \n\n                                            triggers  \n0                          [0.0, 0.0, 0.0, 1.0, 0.0]  \n1                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n4                               [0.0, 0.0, 1.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>episode</th>\n      <th>speakers</th>\n      <th>emotions</th>\n      <th>utterances</th>\n      <th>triggers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>utterance_0</td>\n      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n      <td>[also I was the point person on my company's t...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>utterance_1</td>\n      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n      <td>[also I was the point person on my company's t...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>utterance_2</td>\n      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n      <td>[also I was the point person on my company's t...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>utterance_3</td>\n      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n      <td>[also I was the point person on my company's t...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>utterance_4</td>\n      <td>[Joey, Rachel, Joey, Rachel]</td>\n      <td>[surprise, sadness, surprise, fear]</td>\n      <td>[But then who? The waitress I went out with la...</td>\n      <td>[0.0, 0.0, 1.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw = pd.read_json(train_data_path)\n",
    "val_data_raw = pd.read_json(val_data_path)\n",
    "test_data_raw = pd.read_json(test_data_path)\n",
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion encoding\n",
    "The emotions are encoded mapping each of them with a specific value. Positive emotion are assigned to positive values the negatives with negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.770033Z",
     "start_time": "2024-01-15T16:09:16.743753500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'surprise' 'fear' 'sadness' 'joy' 'disgust' 'anger']\n"
     ]
    }
   ],
   "source": [
    "emotions = train_data_raw['emotions'].explode().unique()\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.812590600Z",
     "start_time": "2024-01-15T16:09:16.757737500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping:{'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'neutral': 4, 'sadness': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode emotions\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(emotions)\n",
    "print(\"Mapping:\" + str(dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.836111600Z",
     "start_time": "2024-01-15T16:09:16.772541400Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(data, test=False):\n",
    "    tmp = data.copy()\n",
    "    tmp['emotions'] = data['emotions'].apply(lambda x: encoder.transform(x))\n",
    "    if not test:\n",
    "        tmp['triggers'] = data['triggers'].apply(lambda x: [0 if i == np.nan or i == None else i for i in x])\n",
    "    tmp.drop(columns=['episode'], inplace=True)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.888992200Z",
     "start_time": "2024-01-15T16:09:16.788561Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pre_process(train_data_raw)\n",
    "val_data = pre_process(val_data_raw)\n",
    "test_data = pre_process(test_data_raw, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.898748Z",
     "start_time": "2024-01-15T16:09:16.881165100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first row\n",
    "train_data['triggers'].explode().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.926502400Z",
     "start_time": "2024-01-15T16:09:16.896238700Z"
    }
   },
   "outputs": [],
   "source": [
    "class UtteranceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:16.986686400Z",
     "start_time": "2024-01-15T16:09:16.910990900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:17.068424400Z",
     "start_time": "2024-01-15T16:09:16.986686400Z"
    }
   },
   "outputs": [],
   "source": [
    "from baselines import BertBaseline \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:17.142745700Z",
     "start_time": "2024-01-15T16:09:17.064409Z"
    }
   },
   "outputs": [],
   "source": [
    "# This collate function takes care of adding padding to the sequences\n",
    "def collate(batch):\n",
    "    speakers, emotions, utterances, triggers = zip(*batch)\n",
    "    emotions = [torch.tensor(e, dtype=torch.long) for e in emotions]\n",
    "    triggers = [torch.tensor(t, dtype=torch.long) for t in triggers]\n",
    "    return {\n",
    "        'speakers': speakers,\n",
    "        'emotions': torch.nn.utils.rnn.pad_sequence(emotions, batch_first=True, padding_value=-1),\n",
    "        'utterances': utterances,\n",
    "        'triggers': torch.nn.utils.rnn.pad_sequence(triggers, batch_first=True, padding_value=-1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:18.471076600Z",
     "start_time": "2024-01-15T16:09:17.143745200Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BertBaseline()\n",
    "train_dataset = UtteranceDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=0, collate_fn=collate)\n",
    "val_loader = DataLoader(UtteranceDataset(val_data), batch_size=2, shuffle=False, num_workers=0, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:18.548422700Z",
     "start_time": "2024-01-15T16:09:18.466556900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speakers': (['Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler'], ['Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler']), 'emotions': tensor([[ 4,  4,  4,  4,  6, -1, -1],\n",
      "        [ 4,  4,  4,  4,  6,  4,  4]]), 'utterances': ([\"also I was the point person on my company's transition from the KL-5 to GR-6 system.\", \"You must've had your hands full.\", 'That I did. That I did.', \"So let's talk a little bit about your duties.\", 'My duties?  All right.'], [\"also I was the point person on my company's transition from the KL-5 to GR-6 system.\", \"You must've had your hands full.\", 'That I did. That I did.', \"So let's talk a little bit about your duties.\", 'My duties?  All right.', \"Now you'll be heading a whole division, so you'll have a lot of duties.\", 'I see.']), 'triggers': tensor([[ 0,  0,  0,  1,  0, -1, -1],\n",
      "        [ 0,  0,  0,  0,  0,  1,  0]])}\n"
     ]
    }
   ],
   "source": [
    "# Fix all possible sources of randomness\n",
    "# torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:09:32.940815Z",
     "start_time": "2024-01-15T16:09:18.544402100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name        | Type      | Params\n",
      "------------------------------------------\n",
      "0 | model       | BertModel | 109 M \n",
      "1 | emotion_clf | CLF       | 99.3 K\n",
      "2 | trigger_clf | CLF       | 98.8 K\n",
      "------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "438.722   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff1a1aca47b34530b9f2ec570bba2b76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 7])\n",
      "torch.Size([2, 11])\n",
      "torch.Size([2, 3, 11])\n",
      "torch.Size([2, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 14, 7])\n",
      "torch.Size([2, 14])\n",
      "torch.Size([2, 3, 14])\n",
      "torch.Size([2, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fed2124c0844f4c824a10b01a0088b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 2\n",
    "\n",
    "train_model(BertBaseline, \n",
    "            \"bert_baseline\", \n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            epochs=epochs, \n",
    "            hyperparameters={\"lr\":lr})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
